---
title: "STA 141A: Final Project"
author: "Zen Yoshida 921437539"
output: html_document
---
  
![Mouse Riding a Scooter](http://3.bp.blogspot.com/-jmYxaeosVEI/TmSHjKjlIxI/AAAAAAAAAzQ/MVIaagLrNbk/s1600/funny+mouse+pics.jpg)

***
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, fig.align = "center")
options(repos = list(CRAN="http://cran.rstudio.com/"))
library(tidyverse)
library(knitr)
library(ggplot2)

# Load the data
session <- list()
for (i in 1:18) {
  session[[i]] <- readRDS(paste("session", i, '.rds', sep=''))
}

n.session <- length(session)
```
***


# Abstract


  This project aims to analyze a subset of data collected by Steinmetz et al. (2019) from mouse experiments involving visual stimuli and neural activity recordings. The primary objective is to build a predictive model that can accurately predict the outcome of each trial based on the neural activity data and stimulus information. The project is divided into three main parts: exploratory data analysis, data integration, and model training and prediction. Through these analyses, we seek to gain insights into the data structures, neural activity patterns, and session-specific variations. The performance of the predictive model will be evaluated using test sets randomly selected from two sessions. This project report presents the findings and discusses the implications of the analysis.



# Section 1: Introduction

  The study involves 10 mice and 39 sessions. The experiments consisted of presenting visual stimuli to the mice on two screens while recording the activity of neurons in their visual cortex. Each session included multiple trials, with the mice making decisions based on the visual stimuli and receiving feedback in the form of rewards or penalties.

  The visual stimuli varied in contrast levels, ranging from 0 to 1, with 0 indicating the absence of a stimulus. The mice used a wheel controlled by their forepaws to make decisions. The outcome of their decisions depended on the relative contrast levels of the stimuli, and different rules were applied based on the specific conditions.

  The data provided in this project focuses on the spike trains of neurons recorded during the trials. Spike trains are collections of timestamps indicating the firing of neurons. Specifically, we analyze the spike trains from the onset of the stimuli to 0.4 seconds after the onset.

  For this analysis, we only consider 18 sessions. There are RDS files available, each corresponding to a specific session. These files contain records of the experiments, including the mouse's name and the date of the experiment, number of brain areas tested, the number of neurons looked at, and more. There are five variables to pay attention to in the data set, though all will not be used in this report:

**feedback_type:** type of the feedback, 1 for success and -1 for failure

**contrast_left:** contrast of the left stimulus

**contrast_right:** contrast of the right stimulus

**time:** centers of the time bins for spks

**spks:** numbers of spikes of neurons in the visual cortex in time bins defined in time

**brain_area:** area of the brain where each neuron lives
 

# Section 2: Exploratory Data Analysis

## Homogeneity and Heterogeneity
```{r, echo=FALSE, eval = TRUE}


col_names <- c("Mouse Name", "# Brain Areas", "# Neurons", "# Trials", "Success Rate")
meta <- tibble(
  mouse_name = rep('name', n.session),
  n_brain_area = rep(0, n.session),
  n_neurons = rep(0, n.session),
  n_trials = rep(0, n.session),
  success_rate = rep(0, n.session)
)

for (i in 1:n.session) {
  tmp <- session[[i]]
  meta[i, "mouse_name"] <- tmp$mouse_name
  meta[i, "n_brain_area"] <- length(unique(tmp$brain_area))
  meta[i, "n_neurons"] <- dim(tmp$spks[[1]])[1]
  meta[i, "n_trials"] <- length(tmp$feedback_type)
  meta[i, "success_rate"] <- mean(tmp$feedback_type + 1) / 2
}


colnames(meta) <- col_names


knitr::kable(meta, format = "html", table.attr = "class='table table-striped'", digits = 2)

```
  
  Here is a table exploring how the data is organized in the 18 Sessions. The date column is removed as it is not relevant to the project. What will be important, however, is to note how the number of brain areas and the number of neurons constantly fluctuates between Sessions. This suggests that the dataset exhibits heterogeneity between the mice. Even among Sessions of the same mice, no two Sessions are similar. 
  
***

## Neural Activities within Trials

### Average Spike Count

  To understand the structure within just one Session and one Trial, below is a simple bar graph analyzing the Average Spike Count within each brain area for Session 2, Trial 1. Recall from the graph analyzing the dataset that Session 2 has 5 Brain Areas. The 1070 neurons in this Session are located in CA1, VISl, root, VISpm, POST of the mouse brain. 
  
```{r, echo = FALSE}

area.col <- c("#FF7F00", "#00BFC4", "#E69F00", "#CC79A7", "#56B4E9")

# AVERAGE EXAMPLE

i.s <- 2 # indicator for this session
i.t <- 1 # indicator for this trial 

spk.trial <- session[[i.s]]$spks[[i.t]]
area <- session[[i.s]]$brain_area
spk.count <- apply(spk.trial, 1, sum)


average_spike_count <- aggregate(spk.count ~ area, data = data.frame(area, spk.count), mean)
average_spike_count <- average_spike_count[order(average_spike_count$spk.count), ]

max_spike_count <- max(average_spike_count$spk.count)


ggplot(average_spike_count, aes(x = area, y = spk.count, fill = area)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(values = area.col) +
  labs(title = paste("Average Spike Count per Area in Session", i.s),
       x = "Area", y = "Average Spike Count") +
  ylim(0, max_spike_count * 1.1) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  geom_text(aes(label = format(round(spk.count, digits = 5), nsmall = 3)),
            position = position_dodge(width = 0.5), vjust = -0.5, size = 4, color = "black")




```

Average Spike Count represents the mean number of spikes in the neurons recorded for each of the brain areas. 

### Average Spike Rate

  The graph below analyzes a similar but slightly different component, the Average Spike Rate. To calculate the Average Spike Rate, you would divide the total number of spikes recorded from a neuron during a trial by the duration of the trial. This provides an estimate of the average firing rate of the neuron throughout the trial. Like the graph above, we are looking at single trial from Session 2, Trial 1.
  
```{r, echo = FALSE}



i.s <- 2  # Indicator for the session
i.t <- 1  # Indicator for the trial


spk.trial <- session[[i.s]]$spks[[i.t]]
area <- session[[i.s]]$brain_area


spike.rate <- apply(spk.trial, 1, function(row) sum(row) / length(row))

data <- data.frame(area = area, spike_rate = spike.rate)

average_spike_rate <- aggregate(spike_rate ~ area, data, mean)

average_spike_rate <- average_spike_rate[order(average_spike_rate$spike_rate), ]


max_spike_rate <- max(average_spike_rate$spike_rate)

area.col2 <- c("#FF7F00", "#00BFC4", "#E69F00", "#CC79A7", "#56B4E9")


ggplot(average_spike_rate, aes(x = area, y = spike_rate, fill = area)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(values = area.col2) +
  labs(title = paste("Average Spike Rate per Area in Session", i.s),
       x = "Area", y = "Spike Rate") +
  ylim(0, max_spike_rate * 1.1) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  geom_text(aes(label = format(round(spike_rate, digits = 5), nsmall = 3)),
            position = position_dodge(width = 0.5), vjust = -0.5, size = 4, color = "black")




```

  By dividing the sum of spikes in each row by the length of the row (which represents the number of time bins), the Average Spike Rate can be calculated per time bin. 
  
  Below is the number given when taken the Average Spike Rate for Session 2 Trial 1 without taking in consideration the brain areas. Because heterogeneity is due to the differences in neurons measured in each session, the information about specific neurons can be smoothed over by averaging over their activities. This will become important in Section 2, as with this we can just ignore the differences in brain areas and focus on one unifying number. 
  
```{r, echo = FALSE}


i.s <- 2  # Indicator for the session
i.t <- 1  # Indicator for the trial

spk.trial2 <- session[[i.s]]$spks[[i.t]]
area2 <- session[[i.s]]$brain_area


all_brain_spike.rate <- apply(spk.trial2, 1, function(row) sum(row) / length(row))

ASR_all_brain <- mean(all_brain_spike.rate)

ASR_all_brain

```

  

### Contrast Difference

  An important consideration that will ultimately be critical when making a predictive model for Feedack Type, is contrast difference. Understanding the contrast difference can provide insights into how the mice respond to different levels of visual stimuli and how it influences their decision-making process. By examining the contrast difference, we can explore whether the mice exhibit any biases towards certain stimulus conditions or if they show preferences for specific contrasts. Contrast Difference is provided by the the difference between two variables, Contrast Left and Contrast Right. 
  
```{r, echo = FALSE}

i.s <- 2  # Indicator for the session
i.t <- 1  # Indicator for the trial

contrast_left <- session[[i.s]]$contrast_left[[i.t]]
contrast_right <- session[[i.s]]$contrast_right[[i.t]]


contrast_diff <- abs(contrast_left - contrast_right)

contrast_diff

```

  In Section 2, Trial 1, the Contrast Difference is 0. There is not much to gain from the single number of a trial, so let's explore what Contrast Difference looks like between whole Sections. This can also teach the difference between trials by displaying their contribution to their Session. 
  

```{r, echo=FALSE}

session_2 <- session[[2]]
session_3 <- session[[3]]
session_4 <- session[[4]]

contrast_diff_session_2 <- session_2$contrast_left - session_2$contrast_right
contrast_diff_session_3 <- session_3$contrast_left - session_3$contrast_right
contrast_diff_session_4 <- session_4$contrast_left - session_4$contrast_right


all_contrast_diff <- c(contrast_diff_session_2, contrast_diff_session_3, contrast_diff_session_4)
all_sessions <- factor(rep(c("Session 2", "Session 3", "Session 4"),
                          times = c(length(contrast_diff_session_2),
                                    length(contrast_diff_session_3),
                                    length(contrast_diff_session_4))))


data <- data.frame(Contrast_Difference = all_contrast_diff, Session = all_sessions)


ggplot(data, aes(x = Session, y = Contrast_Difference, fill = Session)) +
  geom_boxplot() +
  scale_fill_manual(values = c("salmon3", "orchid1", "darkorchid4")) +
  labs(title = "Contrast Difference", y = "Contrast Difference") +
  theme_minimal()


```
  
  The boxplot for Session 3 is particularly strange. The median line being at the edge of the interquartile range suggests that the distribution is skewed towards lower Contrast Differences, but there are some extreme positive values that contribute to the upper whisker. There is a dot representing an outlier, meaning there was a trial that exhibted very strange behavior. 
  

# Section 3: Data Integration
## Patterns Across Sessions

### Session 2 Average Spike Rate 

  As established in Section 1, we can do things like consider the Average Spike Rate across the entire Session, not just one Trial. 
  
```{r, echo = FALSE}

i.s <- 2  # Indicator for Session 2


spk.data <- session[[i.s]]$spks
area <- session[[i.s]]$brain_area

all_trials_spike.rate <- sapply(spk.data, function(trial) {
  spike.rate <- apply(trial, 1, function(row) sum(row) / length(row))
  mean(spike.rate)
})

ASR_all_trials <- mean(all_trials_spike.rate)

ASR_all_trials

```

  Taking it a step further, what is the comprehensive average spike rate for every Session? 

```{r, echo = FALSE}

num_sessions <- 18


average_spike_rates <- vector("numeric", length = num_sessions)

for (i.s in 1:num_sessions) {

  spk.data <- session[[i.s]]$spks
  area <- session[[i.s]]$brain_area

  all_trials_spike.rate <- sapply(spk.data, function(trial) {
    spike.rate <- apply(trial, 1, function(row) sum(row) / length(row))
    mean(spike.rate)
  })

  average_spike_rates[i.s] <- mean(all_trials_spike.rate)
}


ASR_all_sessions <- mean(average_spike_rates)

ASR_all_sessions

```

### Comprehensive Average Spike Rate

  Due to the vast number of brain areas across the 18 Sessions, it is difficult to find easy patterns across Sessions. Nonetheless, it is possible to provide some fascinating visual information on what brain areas have higher spike rates.
  
```{r, echo = FALSE}


all_average_spike_rates <- list()

for (i.s in 1:length(session)) {

  spk_rates <- numeric()
  areas <- character()


  for (i.t in 1:length(session[[i.s]]$spks)) {

    spk.trial <- session[[i.s]]$spks[[i.t]]
    area <- session[[i.s]]$brain_area


    spike.rate <- apply(spk.trial, 1, function(row) sum(row) / length(row))


    spk_rates <- c(spk_rates, spike.rate)
    areas <- c(areas, area)
  }

  data <- data.frame(session = i.s, area = areas, spike_rate = spk_rates)

  average_spike_rate <- aggregate(spike_rate ~ session + area, data, mean)

  all_average_spike_rates[[i.s]] <- average_spike_rate
}

combined_average_spike_rates <- do.call(rbind, all_average_spike_rates)


ggplot(data = combined_average_spike_rates, aes(x = factor(session), y = spike_rate, color = area)) +
  geom_point() +
  labs(title = "Comprehensive Spike Rate Analysis (All Areas)",
       x = "Session", y = "Average Spike Rate", color = "Area") +
  scale_x_discrete(breaks = unique(combined_average_spike_rates$session)) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(face = "bold", size = 14))


```

  Plots like these allows for a comparison of the average spike rates across different brain areas within all the Sessions. It helps identify any patterns or trends in the spike rate variations between brain areas and across sessions. Furthermore, due to the large amount of brain areas, it may also be worth looking into the five most commonly seen brain areas across Sessions. After all, it is likely that the numbers from these brain areas will have the largest affect when forming a prediction in Section 3.

```{r, echo = FALSE}



all_average_spike_rates <- list()
all_max_spike_rates <- numeric()


for (i.s in 1:length(session)) {

  spk_rates <- numeric()
  areas <- character()
  

  for (i.t in 1:length(session[[i.s]]$spks)) {

    spk.trial <- session[[i.s]]$spks[[i.t]]
    area <- session[[i.s]]$brain_area
    
    spike.rate <- apply(spk.trial, 1, function(row) sum(row) / length(row))

    spk_rates <- c(spk_rates, spike.rate)
    areas <- c(areas, area)
  }

  data <- data.frame(area = areas, spike_rate = spk_rates)

  average_spike_rate <- aggregate(spike_rate ~ area, data, mean)

  all_average_spike_rates[[i.s]] <- average_spike_rate
}

combined_average_spike_rates <- do.call(rbind, all_average_spike_rates)

top_areas <- head(sort(table(combined_average_spike_rates$area), decreasing = TRUE), 5)


top_data <- combined_average_spike_rates[combined_average_spike_rates$area %in% names(top_areas), ]


average_spike_rate <- aggregate(spike_rate ~ area, top_data, mean)

average_spike_rate <- average_spike_rate[order(average_spike_rate$spike_rate), ]


max_spike_rate <- max(average_spike_rate$spike_rate)


ggplot(average_spike_rate, aes(x = area, y = spike_rate, fill = area)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(values = area.col) +
  labs(title = "Comprehensive Spike Rate Analysis (Top 5 Areas)",
       x = "Area", y = "Average Spike Rate") +
  ylim(0, max_spike_rate * 1.1) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  geom_text(aes(label = format(round(spike_rate, digits = 5), nsmall = 3)),
            position = position_dodge(width = 0.5), vjust = -0.5, size = 4, color = "black")


```

  Overall, due to the incompatibility of brain areas across every Session, it would be best to utilize the technique of finding the average across the brain areas. This is what will be used in the prediction modeling. 


***

# Section 4: Prediction Modeling

## Logistic Regression

 To begin fitting a Logistic Regression Model factoring the Average Spike Rate and Contrast Difference as variables and the Feedback Type as the response, a new dataset called combined_dataset is created. It is essential that the glm() function set to the binomial distribution only takes in the binary values 0 or 1 as the response, so the Feedback Type variable must be changed from -1 to 1 to 0 to 1. 
 
```{r, echo = FALSE}


contrast_diff_dataset <- data.frame(contrast_diff = numeric(0))


for (i.s in 1:18) {

  for (i.t in 1:length(session[[i.s]]$contrast_left)) {

    contrast_left <- session[[i.s]]$contrast_left[[i.t]]
    contrast_right <- session[[i.s]]$contrast_right[[i.t]]
    

    contrast_diff <- abs(contrast_left - contrast_right)
 
    contrast_diff_dataset <- rbind(contrast_diff_dataset, data.frame(contrast_diff))
  }
}

 
```

```{r, echo = FALSE}

avg_spike_rate_dataset <- data.frame(avg_spike_rate = numeric(0))


for (i.s in 1:18) {

  num_trials <- length(session[[i.s]]$spks)
  
  for (i.t in 1:num_trials) {

    spk.trial <- session[[i.s]]$spks[[i.t]]

    neuron_spike_rate <- apply(spk.trial, 1, function(row) sum(row) / length(row))

    avg_spike_rate <- mean(neuron_spike_rate)
    

    avg_spike_rate_dataset <- rbind(avg_spike_rate_dataset, data.frame(avg_spike_rate))
  }
}

 
```

```{r, echo = FALSE}

feedback_type_dataset <- data.frame(feedback_type = character(0))


for (i.s in 1:18) {
  num_trials <- length(session[[i.s]]$spks)

  for (i.t in 1:num_trials) {

    feedback_type <- session[[i.s]]$feedback_type[[i.t]]
    

    if (feedback_type %in% c(-1, 1)) {

      feedback_type <- ifelse(feedback_type == -1, 0, 1)

      feedback_type_dataset <- rbind(feedback_type_dataset, data.frame(feedback_type))
    }
  }
}

names(feedback_type_dataset) <- "outcome"


combined_dataset <- cbind(avg_spike_rate_dataset, contrast_diff_dataset, feedback_type_dataset)

head(combined_dataset)

```

  Next, the Logistic Regression Model is tested prior to the release of the datasets on Monday, to confirm things are working fluidly. To do this, we take the first 100 trials in the combined_dataset and set that aside in a test_dataset to use. The rest of the dataset is set aside in the train_dataset and used in the glm() function.

```{r, echo = FALSE}
set.seed(123)


num_test_trials <- 100


test_dataset <- combined_dataset[1:num_test_trials, ]
train_dataset <- combined_dataset[(num_test_trials + 1):nrow(combined_dataset), ]

model <- glm(outcome ~ avg_spike_rate + contrast_diff, data = train_dataset, family = binomial)

estimates0 <- coef(model)
standarderrors0 <- sqrt(diag(vcov(model)))

cat("Estimates:\n")
cat(estimates0, "\n")

cat("Standard Errors:\n")
cat(standarderrors0, "\n")


predicted_probs <- predict(model, test_dataset, type = "response")

predicted_labels <- ifelse(predicted_probs >= 0.5, 1, 0)


confusion_matrix <- table(test_dataset$outcome, predicted_labels)
confusion_matrix


misclassification_rate <- mean(test_dataset$outcome != predicted_labels)
misclassification_rate


TP <- sum(test_dataset$outcome == 1 & predicted_labels == 1)  # True Positives
FP <- sum(test_dataset$outcome == 0 & predicted_labels == 1)  # False Positives
FN <- sum(test_dataset$outcome == 1 & predicted_labels == 0)  # False Negatives

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)

f1_score <- 2 * (precision * recall) / (precision + recall)
f1_score

```
  
  With a 34% misclassification rate, the result of this initial testing was only mediocre. Under two-thirds of the test were classified correctly. A 0.79 F1 Score represents an acceptable but not great trade-off between correctly identifying positive instances (precision) and capturing all positive instances (recall). This suggests that the model may have a bias or may need further refinement to improve its performance. Somewhat disappointing, but nonetheless interesting. 


# Section 5: Prediction Modeling with Test

  For the culmination of the project, two test datasets are released. This means we can use the entirety of combined_dataset for our training. Combined_dataset_test is created to house the test datasets in the same format as combined_dataset.

```{r, echo = FALSE}

test <- list()
for (i in 1:2) {
  test[[i]] <- readRDS(paste("test", i, '.rds', sep=''))
}


contrast_diff_dataset_test <- data.frame(contrast_diff = numeric(0))


for (i.s in 1:2) {

  for (i.t in 1:length(test[[i.s]]$contrast_left)) {

    contrast_left <- test[[i.s]]$contrast_left[[i.t]]
    contrast_right <- test[[i.s]]$contrast_right[[i.t]]
    
    contrast_diff <- abs(contrast_left - contrast_right)

    contrast_diff_dataset_test <- rbind(contrast_diff_dataset_test, data.frame(contrast_diff))
  }
}

```

```{r, echo = FALSE}

avg_spike_rate_dataset_test <- data.frame(avg_spike_rate = numeric(0))

for (i.s in 1:2) {

  num_trials <- length(test[[i.s]]$spks)

  for (i.t in 1:num_trials) {

    spk.trial <- test[[i.s]]$spks[[i.t]]
    
 
    neuron_spike_rate <- apply(spk.trial, 1, function(row) sum(row) / length(row))
    
  
    avg_spike_rate <- mean(neuron_spike_rate)
   
    avg_spike_rate_dataset_test <- rbind(avg_spike_rate_dataset_test, data.frame(avg_spike_rate))
  }
}


```

```{r, echo = FALSE}

feedback_type_dataset_test <- data.frame(feedback_type = character(0))


for (i.s in 1:2) {

  num_trials <- length(test[[i.s]]$spks)
  

  for (i.t in 1:num_trials) {
  
    feedback_type <- test[[i.s]]$feedback_type[[i.t]]
  
    if (feedback_type %in% c(-1, 1)) {
 
      feedback_type <- ifelse(feedback_type == -1, 0, 1)
      
    
      feedback_type_dataset_test <- rbind(feedback_type_dataset_test, data.frame(feedback_type))
    }
  }
}



names(feedback_type_dataset_test) <- "outcome"

combined_dataset_test <- cbind(avg_spike_rate_dataset_test, contrast_diff_dataset_test, feedback_type_dataset_test)

head(combined_dataset_test)

```


```{r, echo = FALSE}



model2 <- glm(outcome ~ avg_spike_rate + contrast_diff, data = combined_dataset, family = binomial)

estimates <- coef(model2)
standarderrors <- sqrt(diag(vcov(model2)))



cat("Estimates:\n")
cat(estimates, "\n")

cat("Standard Errors:\n")
cat(standarderrors, "\n")



predicted_probs <- predict(model2, combined_dataset_test, type = "response")


predicted_labels <- ifelse(predicted_probs >= 0.5, 1,0)


confusion_matrix <- table(combined_dataset_test$outcome, predicted_labels)
confusion_matrix

misclassification_rate <-  mean(combined_dataset_test$outcome != predicted_labels)
misclassification_rate


TP <- sum(combined_dataset_test$outcome == 1 & predicted_labels == 1)  # True Positives
FP <- sum(combined_dataset_test$outcome == 0 & predicted_labels == 1)  # False Positives
FN <- sum(combined_dataset_test$outcome == 1 & predicted_labels == 0)  # False Negatives

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)

f1_score <- 2 * (precision * recall) / (precision + recall)
f1_score

```

  With a misclassification rate of 0.275, the final model improved slightly compared to the practice run. An F1 score was also included, which at 0.84 indicates a relatively good balance between precision and recall. This suggests that the model has a reasonable trade-off between correctly identifying positive instances (precision) and capturing all positive instances (recall).


```{r, echo = FALSE}
library(ggplot2)

results <- data.frame(predicted_probs, true_outcome = combined_dataset_test$outcome)


ggplot(results, aes(x = predicted_probs, y = true_outcome)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "Predicted Probabilities", y = "True Outcome") +
  ggtitle("Logistic Regression Results") +
  theme_minimal()

```

  Lastly, a graph is included to analyze the effectiveness of the Logistic Regression Model. The scatter plot helps visualize the relationship between the predicted probabilities and the true outcomes. It provides a visual representation of how well the logistic regression model predicts the outcomes. The points are scattered across the plot, indicating the varying predicted probabilities for different instances.

  Additionally, a smooth curve is fitted to the scatter plot using the logistic regression method. This curve represents the estimated relationship between the predicted probabilities and the true outcomes, based on the model. The curve provides insights into the overall trend and pattern in the data.


# Discussion
  
  Overall, utilizing the Average Spike Rate and Contrast Difference as the variables may not have been the best option to assess Feedback Type. 27.5% misclassification rate is not horrible, but it also suggests a high amount of possible improvement. The 0.84 F1 Score further tells me that I was headed in a good direction. The estimates and standard errors were also not wildly suspicious. Despite not being able to create the perfect prediction model, the process taught me significantly, and I am proud of what I was able to do. Given more experience and time, I would have liked to explore other variables and see how they would improve the model. More exploration into utilizing brain areas may have been warranted as well.
  
  
![My Computer Mouse After Finishing This Project](http://1.bp.blogspot.com/-d_dH5GJhtuk/TmSHlnpFZEI/AAAAAAAAAzc/CYVUSfCqxSw/s1600/Funny+pictures+of+computer+mouse.jpg)  

# Reference

  Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x


